## Description
This directory includes source codes for machine learning.
Ordinary least squares (OLS), partial least squares (PLS), Ridge, and Lasso regressions were implemented using the scikit-learn package. Experimental yields were transformed using the logit function, while the machine learning model outputs were converted back using the inverse logit function so that the predictions fell within the 0â€“100 range. Nested leave-one-group-out cross-validation was performed based on different types of pyridones. In the outer loop, data associated with one pyridone were left out for model evaluation, while data from the remaining pyridones were used for training. Within this training set (inner loop), the data were again split such that samples from one pyridone were used for validation and the rest for training, enabling selection of the optimal model hyperparameters.

To further improve model performance and interpretability, recursive feature elimination (RFE) was employed to reduce the number of explanatory variables. RFE was applied within the inner loop, ensuring that the test data used for model evaluation remained unseen. Model accuracy was assessed using root mean squared error (RMSE), allowing the values to be directly interpreted as yield prediction errors. After selecting the best-performing machine learning model, it was retrained on the entire dataset with RFE applied. The number of features (coefficients) that yielded the lowest RMSE was identified, and these selected coefficients were then used to determine the reaction mechanism.